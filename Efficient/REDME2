python predict.py \
  --ckpt "./runs/effnetv2_s_384/best.ckpt" \
  --model efficientnetv2_s \
  --img-size 384 \
  --input "/path/to/test_images"

python - <<'PY'
import torch, torchvision, torchaudio
print("torch:", torch.__version__)
print("torchvision:", torchvision.__version__)
print("torchaudio:", torchaudio.__version__)
print("cuda_available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("device:", torch.cuda.get_device_name(0))
PY


python predict.py \
  --ckpt "runs/tf_effnetv2_s_in21k_ft1k_384/best.ckpt" \
  --model tf_efficientnetv2_s_in21k_ft_in1k \
  --img-size 384 \
  --input "./test_images" \
  --resize-mode pad --bg black \
  --tta \
  --threshold 0.60 \
  --topk 3 \
  --save-csv "runs/preds.csv" \
  --save-per-class "runs/preds_split"

python predict.py \
  --ckpt "runs/effv2_s_phaseB/best.ckpt" \
  --model tf_efficientnetv2_s_in21k_ft_in1k \
  --img-size 384 \
  --input "test_crops" \
  --resize-mode pad --bg black \
  --tta \
  --threshold 0.60 \
  --topk 3 \
  --save-csv "runs/preds.csv" \
  --save-per-class "runs/preds_split" \
  --eval --eval-out "runs/eval_from_predict" \
  --export-miscls --miscls-limit 50

python predict.py \
  --ckpt "runs/effv2_s_phaseB/best.ckpt" \
  --model tf_efficientnetv2_s_in21k_ft_in1k \
  --img-size 384 \
  --input "/home/yourname/effnetv2_run/cls_dataset_test/test" \
  --resize-mode pad --bg black \
  --tta \
  --threshold 0.60 \
  --topk 3 \
  --save-csv "runs/preds.csv" \
  --save-per-class "runs/preds_split" \
  --eval --eval-out "runs/eval_from_predict" \
  --export-miscls --miscls-limit 50

python predict.py \
  --ckpt "runs/effv2_s_phaseB/best.ckpt" \
  --model tf_efficientnetv2_s_in21k_ft_in1k \
  --img-size 384 \
  --input "cls_dataset_test/test" \
  --resize-mode pad --bg black \
  --eval --eval-out "runs/eval_from_predict" \
  --save-csv "runs/preds.csv" --save-per-class "runs/preds_split"

python train_effnetv2.py \
  --data "./cls_dataset" \
  --out "./runs/effv2_s_1phase" \
  --model tf_efficientnetv2_s_in21k_ft_in1k \
  --img-size 384 \
  --batch-size 32 \
  --epochs 30 \
  --lr 1e-4 \
  --head-lr-mult 10 \
  --warmup-epochs 5 \
  --min-lr 1e-6 \
  --wd 1e-4 \
  --aug light \
  --label-smoothing 0.1 \
  --weighted-sampler --weighted-loss \
  --amp

python predict.py \
  --ckpt runs/effv2_s_384/best.ckpt \
  --model tf_efficientnetv2_s_in21k_ft_in1k \
  --input ./cls_dataset/val \
  --img-size 384 --resize-mode pad \
  --speed --speed-csv runs/speed_log.csv --warmup 10 \
  --eval --eval-out runs/eval_from_predict

python train_effnetv2.py \
  --data ./cls_dataset \
  --out ./runs/effv2_wr_t0_5 \
  --model efficientnetv2_s \
  --img-size 384 --batch-size 32 \
  --epochs 60 \
  --lr 5e-5 --head-lr-mult 10 \
  --lr-schedule cosine_wr --t0 5 --t-mult 2 \
  --min-lr 1e-6 --warmup-epochs 3 \
  --wd 1e-4 --aug light --label-smoothing 0.1 \
  --weighted-sampler --weighted-loss \
  --amp --tensorboard

python predict.py \
  --ckpt "runs/steplader_epoch50S/best.ckpt" \
  --model tf_efficientnetv2_s \
  --img-size 384 \
  --input "/home/yanamaoo/effnetv2_run/cls_dataset_test/" \
  --resize-mode pad --bg black \
  --eval --eval-out "runs/eval_from_predict_steplader_epoch50S" \
  --save-csv "runs/preds_steplader_epoch50S.csv" \
  --save-per-class "runs/preds_split"

python - << 'PY'
import torch

ckpt_path = "runs/steplader_epoch50S/best.ckpt"      # ← あなたのckptへのパス
ckpt = torch.load(ckpt_path, map_location="cpu")

# 学習時のクラス並び順をこのリストに正しく入れる
ckpt["class_names"] = [
    "脚立1段目の人",
    "脚立2段目の人",
    "脚立を跨ぐ人",
    "脚立上の安全な人",
    "脚立上の不安定姿勢の人",
]

torch.save(ckpt, ckpt_path)
print("✅ class_names を追記して保存し直しました")
PY

python train_effnetv2.py \
  --data "./cls_dataset" \
  --out "./runs/exp_shiftresize_focal_freeze4" \
  --model tf_efficientnetv2_s \
  --img-size 384 \
  --batch-size 32 \
  --epochs 50 \
  --lr 1e-4 \
  --min-lr 1e-6 \
  --wd 1e-4 \
  --warmup-epochs 3 \
  --lr-schedule cosine_wr --T0 5 --T-mult 2 \
  --aug light \
  --amp \
  --tensorboard \
  --freeze-upto 4 \
  --focal-loss --focal-gamma 2.0 \
  --weighted-loss



